{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from queue import PriorityQueue\n",
    "import ipywidgets as widgets\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from utils import *\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import logging"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Configure logging to output to PyCharm's console\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def add_node_with_edges(graph, node_name):\n",
    "    \"\"\"\n",
    "    Add a node to the graph and allow the user to input related edges with direction using widgets in Jupyter Notebook.\n",
    "    Displays immediate edge information on addition and logs actions to console.\n",
    "\n",
    "    Parameters:\n",
    "    graph (nx.DiGraph): The directed graph to add the node and edges to.\n",
    "    node_name (str): The name of the node to add.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Add the node to the graph\n",
    "    graph.add_node(node_name)\n",
    "    display(HTML(f\"<b>Notification:</b> Node '{node_name}' has been added to the graph.\"))\n",
    "    logger.info(f\"Node '{node_name}' has been added to the graph.\")\n",
    "\n",
    "    # Define output widget\n",
    "    global node_dropdown, user_text, root_text, direction_dropdown, output\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Function to handle edge addition\n",
    "    def add_edge(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<b>Notification:</b> Node '{node_name}' has been added to the graph.\"))\n",
    "            logger.info(f\"Add Edge button clicked for node '{node_name}'.\")\n",
    "\n",
    "            try:\n",
    "                # Get widget values\n",
    "                target_node = node_dropdown.value\n",
    "                user_prob = float(user_text.value)\n",
    "                root_prob = float(root_text.value)\n",
    "                direction = direction_dropdown.value\n",
    "\n",
    "                # Validate probabilities\n",
    "                if not (0.0 <= user_prob <= 1.0 and 0.0 <= root_prob <= 1.0):\n",
    "                    display(HTML(\"<b>Error:</b> Probabilities must be in the range [0.0, 1.0]. Please try again.\"))\n",
    "                    logger.error(f\"Invalid probabilities: user={user_prob}, root={root_prob}\")\n",
    "                    return\n",
    "\n",
    "                # Prepare edge information\n",
    "                edge_info = f\"Edge Info: user={user_prob}, root={root_prob}, direction={direction}\"\n",
    "\n",
    "                # Add edge based on direction\n",
    "                if direction == \"To Target\":\n",
    "                    graph.add_edge(node_name, target_node, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Edge from '{node_name}' to '{target_node}' ({edge_info})\"\n",
    "                elif direction == \"From Target\":\n",
    "                    graph.add_edge(target_node, node_name, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Edge from '{target_node}' to '{node_name}' ({edge_info})\"\n",
    "                else:  # Bidirectional\n",
    "                    graph.add_edge(node_name, target_node, user=user_prob, root=root_prob)\n",
    "                    graph.add_edge(target_node, node_name, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Bidirectional edge between '{node_name}' and '{target_node}' ({edge_info})\"\n",
    "\n",
    "                # Display and log edge info immediately\n",
    "                display(HTML(f\"<b>Notification:</b> {edge_msg} has been added.\"))\n",
    "                logger.info(f\"{edge_msg} has been added.\")\n",
    "                display_widgets()  # Redisplay widgets for next edge\n",
    "            except ValueError:\n",
    "                display(HTML(\"<b>Error:</b> Invalid input for probabilities. Please enter valid numbers.\"))\n",
    "                logger.error(\"Invalid input for probabilities.\")\n",
    "\n",
    "    # Function to handle stopping\n",
    "    def stop_adding(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<b>Notification:</b> Finished adding edges for node '{node_name}'.\"))\n",
    "            logger.info(f\"Finished adding edges for node '{node_name}'.\")\n",
    "\n",
    "    # Function to display widgets\n",
    "    def display_widgets():\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            # Get list of existing nodes\n",
    "            existing_nodes = list(graph.nodes())\n",
    "            if not existing_nodes:\n",
    "                display(HTML(\"<b>Warning:</b> No existing nodes in the graph.\"))\n",
    "                logger.warning(\"No existing nodes in the graph.\")\n",
    "                return\n",
    "\n",
    "            # Create widgets\n",
    "            global node_dropdown, user_text, root_text, direction_dropdown\n",
    "            node_dropdown = widgets.Dropdown(\n",
    "                options=existing_nodes,\n",
    "                description='Target Node:',\n",
    "                disabled=False\n",
    "            )\n",
    "            user_text = widgets.FloatText(\n",
    "                value=0.0,\n",
    "                description='User Prob:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            root_text = widgets.FloatText(\n",
    "                value=0.0,\n",
    "                description='Root Prob:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            direction_dropdown = widgets.Dropdown(\n",
    "                options=[\"To Target\", \"From Target\", \"Bidirectional\"],\n",
    "                description='Edge Direction:',\n",
    "                disabled=False\n",
    "            )\n",
    "            add_button = widgets.Button(description=\"Add Edge\")\n",
    "            stop_button = widgets.Button(description=\"Stop\")\n",
    "\n",
    "            # Assign button callbacks with debug logging\n",
    "            def on_add_button_clicked(b):\n",
    "                logger.info(\"Add Edge button event triggered.\")\n",
    "                add_edge(b)\n",
    "\n",
    "            def on_stop_button_clicked(b):\n",
    "                logger.info(\"Stop button event triggered.\")\n",
    "                stop_adding(b)\n",
    "\n",
    "            add_button.on_click(on_add_button_clicked)\n",
    "            stop_button.on_click(on_stop_button_clicked)\n",
    "\n",
    "            # Display widgets and initial message\n",
    "            display(HTML(f\"<b>Adding edges from/to '{node_name}':</b>\"))\n",
    "            display(node_dropdown, user_text, root_text, direction_dropdown, add_button, stop_button)\n",
    "\n",
    "    # Initial display of widgets\n",
    "    display(output)\n",
    "    display_widgets()"
   ],
   "id": "f7f25772bc7447f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Original graph setup\n",
    "G_original = nx.DiGraph()\n",
    "G_original.add_nodes_from([\"Attacker\", \"Data Server\"])\n",
    "edges = [\n",
    "    (\"Attacker\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 1\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 2\", \"Host 3\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 2\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 2\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Host 2\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 3\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Web Server\", \"File Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"Web Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"File Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04})\n",
    "]\n",
    "G_original.add_edges_from(edges)\n",
    "\n",
    "G_new = G_original.copy()\n",
    "add_node_with_edges(G_new, \"New node\")\n",
    "\n"
   ],
   "id": "a60ffc5d033479e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "plt.figure(figsize=(30, 25))\n",
    "\n",
    "# Cố định layout để lần nào cũng ra vị trí giống nhau\n",
    "pos = nx.spring_layout(G_new, seed=42)\n",
    "\n",
    "# Vẽ nodes\n",
    "nx.draw_networkx_nodes(G_new, pos, node_color='orange', node_size=2000)\n",
    "\n",
    "# Vẽ labels nodes\n",
    "nx.draw_networkx_labels(G_new, pos, font_size=20, font_weight='bold')\n",
    "\n",
    "# Vẽ edges với mũi tên và màu xám\n",
    "nx.draw_networkx_edges(\n",
    "    G_new, pos,\n",
    "    edge_color='gray',\n",
    "    arrows=True,\n",
    "    arrowsize=50,\n",
    "    width=2,\n",
    "    connectionstyle='arc3,rad=0.1'  # Cạnh hơi cong cho đẹp\n",
    ")\n",
    "\n",
    "# Vẽ label trọng số cạnh\n",
    "edge_labels = {(u, v): f\"u={d['user']},r={d['root']}\" for u, v, d in G_new.edges(data=True)}\n",
    "nx.draw_networkx_edge_labels(G_new, pos, edge_labels=edge_labels, font_size=20)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"graph.png\")\n",
    "plt.show()\n"
   ],
   "id": "4b79226cb400a676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DQNWithBias(nn.Module):\n",
    "    def __init__(self, base_model, old_num_nodes, new_num_nodes, old_honeypot_nodes, new_honeypot_nodes):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.old_num_nodes = old_num_nodes\n",
    "        self.new_num_nodes = new_num_nodes\n",
    "        self.old_space_size = 2 * old_honeypot_nodes**2\n",
    "        self.new_space_size = 2 * new_honeypot_nodes**2\n",
    "        self.alpha = nn.Parameter(torch.Tensor([1]))\n",
    "        self.beta = nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "        # Tạo mask phân biệt action cũ và mới dựa trên cantor pairing\n",
    "        self.register_buffer('is_old_mask', self._create_old_mask())\n",
    "        print(self.is_old_mask)\n",
    "    \n",
    "    def _is_old_action(self, idx):\n",
    "        x, y = inverse_cantor(idx)\n",
    "        print(x,y)\n",
    "        return x < (self.old_num_nodes-1) and y < (self.old_num_nodes-1)\n",
    "\n",
    "    def _create_old_mask(self):\n",
    "        mask = []\n",
    "        for idx in range(self.new_space_size):\n",
    "            mask.append(self._is_old_action(idx))\n",
    "        return torch.tensor(mask, dtype=torch.bool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_raw = self.model(x)  # shape: [batch_size, new_space_size]\n",
    "\n",
    "        # Tách q_old và q_new bằng mask\n",
    "        q_old = q_raw[:, self.is_old_mask]        # các action cũ\n",
    "        q_new = q_raw[:, ~self.is_old_mask]       # các action mới\n",
    "\n",
    "        # Áp dụng correction chỉ với phần action mới    \n",
    "        q_new_corrected = self.alpha * q_new + self.beta\n",
    "\n",
    "        # Kết hợp lại theo thứ tự action ban đầu\n",
    "        q_corrected = torch.empty_like(q_raw)\n",
    "        q_corrected[:, self.is_old_mask] = q_old\n",
    "        q_corrected[:, ~self.is_old_mask] = q_new_corrected\n",
    "\n",
    "        return q_corrected"
   ],
   "id": "6f0b24590ed41913",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Khởi tạo môi trường để lấy kích thước\n",
    "env_original = NetworkSecurityEnv(G_original, global_weighted_random_attack)\n",
    "env_new = NetworkSecurityEnv(G_new, global_weighted_random_attack)\n",
    "\n",
    "# Số node trong state (bao gồm Data Server, trừ Attacker)\n",
    "old_num_nodes = env_original.num_nodes\n",
    "new_num_nodes = env_new.num_nodes\n",
    "\n",
    "# Không gian hành động dựa trên honeypot_nodes\n",
    "old_action_space_size = env_original.get_action_space_size()\n",
    "new_action_space_size = env_new.get_action_space_size()\n",
    "\n",
    "model_old =  DQN(old_num_nodes, old_action_space_size)\n",
    "model_load = torch.load(\"./7-nodes model/dqn_model.pth\")\n",
    "model_old.load_state_dict(model_load['policy_net_state_dict'])\n",
    "model_new = DQN(new_num_nodes, new_action_space_size)\n",
    "\n",
    "\n",
    "# \n",
    "with torch.no_grad():\n",
    "    # Copy fc1, fc2, fc3 như bình thường\n",
    "    model_new.fc1.weight[:, :old_num_nodes] = model_old.fc1.weight[:, :old_num_nodes]\n",
    "    model_new.fc1.bias.copy_(model_old.fc1.bias)\n",
    "    model_new.fc2.load_state_dict(model_old.fc2.state_dict())\n",
    "    model_new.fc3.load_state_dict(model_old.fc3.state_dict())\n",
    "\n",
    "    # Tập chỉ số toàn bộ action mới\n",
    "    all_new_indices = set(range(new_action_space_size))\n",
    "\n",
    "    # Tập các chỉ số action cũ đã copy\n",
    "    old_indices_mapped = set()\n",
    "    for idx in range(old_action_space_size):\n",
    "        i, j = inverse_cantor(idx)\n",
    "        if i < env_original.num_honeypot_nodes and j < env_original.num_honeypot_nodes:\n",
    "            model_new.fc4.weight[idx].copy_(model_old.fc4.weight[idx])\n",
    "            model_new.fc4.bias[idx].copy_(model_old.fc4.bias[idx])\n",
    "            old_indices_mapped.add(idx)\n",
    "\n",
    "    new_indices = list(all_new_indices - old_indices_mapped)\n",
    "\n",
    "    # Khởi tạo phần mở rộng fc4.weight, bias cho các chỉ số mới\n",
    "    for idx in new_indices:\n",
    "        torch.nn.init.xavier_uniform_(model_new.fc4.weight[idx:idx+1])\n",
    "        model_new.fc4.bias[idx] = 0.0\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(model_new.fc1.weight[:, old_num_nodes:])\n"
   ],
   "id": "4ba507b0688fafdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"FC4 weights:\")\n",
    "print(model_new.fc4.weight)\n",
    "\n",
    "print(\"\\nFC4 bias:\")\n",
    "print(model_new.fc4.bias)"
   ],
   "id": "728a66388ca7729e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to check if alpha is saturated\n",
    "def is_alpha_saturated(alpha_history, k_consecutive, target_update_freq, alpha_threshold):\n",
    "    \"\"\"\n",
    "    Check if the last k_consecutive episodes' alpha values are saturated.\n",
    "\n",
    "    Args:\n",
    "        alpha_history (list): List of alpha values recorded during training.\n",
    "        k_consecutive (int): Number of consecutive episodes to check for saturation.\n",
    "        target_update_freq (int): Frequency of alpha updates in episodes.\n",
    "        alpha_threshold (float): Maximum allowed difference between consecutive alpha values.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if alpha is saturated, False otherwise.\n",
    "    \"\"\"\n",
    "    num_alpha_updates = k_consecutive // target_update_freq + (1 if k_consecutive % target_update_freq else 0)\n",
    "    if len(alpha_history) < num_alpha_updates + 1:\n",
    "        return False\n",
    "    recent_alphas = alpha_history[-(num_alpha_updates + 1):]\n",
    "    differences = [abs(recent_alphas[i] - recent_alphas[i-1]) for i in range(1, len(recent_alphas))]\n",
    "    return all(diff < alpha_threshold for diff in differences)"
   ],
   "id": "24f119c4a95be385",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Khởi tạo môi trường và mô hình\n",
    "env = NetworkSecurityEnv(G_new, global_weighted_random_attack)\n",
    "model = DQNWithBias(model_new, old_num_nodes, new_num_nodes, env_original.num_honeypot_nodes, env_new.num_honeypot_nodes)\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    if not (\"fc4\" in name or \"fc1\" in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Flag to track if bias correction is stopped\n",
    "bias_correction_active = True\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': [model.alpha], 'weight_decay': 0.0},\n",
    "    {'params': [model.beta], 'weight_decay': 1e-4},\n",
    "    {'params': [p for n, p in model.model.named_parameters() if \"fc4\" in n or \"fc1\" in n], 'weight_decay': 1e-4}\n",
    "], lr=0.01, momentum=0.8, nesterov=True)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=5, verbose=True, min_lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity=10000)\n",
    "target_update_freq = 8\n",
    "batch_size = 16\n",
    "num_episodes = batch_size * 20\n",
    "losses = []\n",
    "\n",
    "alpha_history = []\n",
    "beta_history = []\n",
    "episode_history = []\n",
    "exploration_counter = defaultdict(int)\n",
    "successes = 0\n",
    "exploration_done = False\n",
    "\n",
    "# Early stopping parameters for alpha saturation\n",
    "k_consecutive = 15  # Number of consecutive episodes to check\n",
    "alpha_threshold = 0.001  # Threshold for alpha difference\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_loss = 0\n",
    "    episode_steps = 0\n",
    "\n",
    "    while not done:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "        if  exploration_done == False:\n",
    "            action_idx, exploration_done = sample_exploration_index(new_action_space_size, env.num_honeypot_nodes, env_original.num_honeypot_nodes, exploration_counter, 10)\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = model(state_tensor).squeeze(0)  # shape: [action_space_size]\n",
    "                valid_indices = [idx for idx in range(new_action_space_size) if is_valid_index(idx, env.num_honeypot_nodes)]\n",
    "                valid_q_values = q_values[valid_indices]\n",
    "                max_idx_in_valid = torch.argmax(valid_q_values).item()\n",
    "                action_idx = valid_indices[max_idx_in_valid]\n",
    "\n",
    "        action = index_to_action(action_idx, env.num_honeypot_nodes)\n",
    "        next_state, reward, done, path, captured = env.step(action)\n",
    "        replay_buffer.push(state, action_idx, reward, next_state, done)\n",
    "        state = next_state\n",
    "        episode_steps += 1\n",
    "\n",
    "        honeypot_nodes = []\n",
    "        for i in range(2):\n",
    "            node_idx = np.argmax(action[i])\n",
    "            honeypot_nodes.append(env.honeypot_nodes[node_idx])  # Sử dụng honeypot_nodes\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        if reward == 1:\n",
    "            print(path)\n",
    "            print(f\"Success\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "            successes += 1\n",
    "        elif reward == -1:\n",
    "            print(path)\n",
    "            print(f\"Failed\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "            states_tensor = torch.FloatTensor(states)\n",
    "            actions_tensor = torch.LongTensor(actions)\n",
    "            rewards_tensor = torch.FloatTensor(rewards)\n",
    "            next_states_tensor = torch.FloatTensor(next_states)\n",
    "            dones_tensor = torch.FloatTensor(dones)\n",
    "\n",
    "            if not (actions_tensor >= 0).all() or not (actions_tensor < new_action_space_size).all():\n",
    "                print(f\"Invalid actions in batch at episode {episode}\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            q_pred = model(states_tensor)\n",
    "\n",
    "            if torch.isnan(q_pred).any() or torch.isinf(q_pred).any():\n",
    "                print(f\"Warning: NaN or Inf in q_pred at episode {episode}\")\n",
    "                continue\n",
    "\n",
    "            q_pred_actions = q_pred.gather(1, actions_tensor.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                q_next = model(next_states_tensor)\n",
    "                q_next_max = q_next.max(1)[0]\n",
    "                q_target = rewards_tensor + (1 - dones_tensor) * 0.99 * q_next_max\n",
    "\n",
    "            loss = criterion(q_pred_actions, q_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / max(episode_steps, 1)\n",
    "    if episode >= batch_size:\n",
    "        losses.append(avg_loss)\n",
    "        scheduler.step(avg_loss)\n",
    "    if episode % target_update_freq == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        alpha_history.append(model.alpha.item())\n",
    "        beta_history.append(model.beta.item())\n",
    "        episode_history.append(episode)\n",
    "\n",
    "        # Check if alpha is saturated and bias correction should stop\n",
    "        if bias_correction_active and is_alpha_saturated(alpha_history, k_consecutive, target_update_freq, alpha_threshold):\n",
    "            print(f\"\\nStopping bias correction at episode {episode}: alpha has saturated (last {k_consecutive} episodes' alpha differences < {alpha_threshold})\")\n",
    "      \n",
    "            # Freeze alpha and beta\n",
    "            model.alpha.requires_grad = False\n",
    "            model.beta.requires_grad = False\n",
    "            # Reconfigure optimizer to exclude alpha and beta\n",
    "            optimizer = torch.optim.SGD([\n",
    "                {'params': [p for n, p in model.model.named_parameters() if \"fc4\" in n or \"fc1\" in n], 'weight_decay': 1e-4}\n",
    "            ], lr=current_lr, momentum=0.8, nesterov=True)\n",
    "            bias_correction_active = False\n",
    "\n",
    "dsp = (successes / num_episodes) * 100\n",
    "print(f\"\\nDefense success probability: {dsp:.2f}%\")"
   ],
   "id": "583de22501bfe22e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"FC4 weights:\")\n",
    "print(model_new.fc4.weight)\n",
    "\n",
    "print(\"\\nFC4 bias:\")\n",
    "print(model_new.fc4.bias)"
   ],
   "id": "65693aa5fe968fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(batch_size, num_episodes + 1), losses)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Training Loss over Episodes')\n",
    "plt.show()\n"
   ],
   "id": "dd3d5900f1a60bf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"FC4 weights:\")\n",
    "print(model_new.fc4.weight)\n",
    "\n",
    "print(\"\\nFC4 bias:\")\n",
    "print(model_new.fc4.bias)\n",
    "print(np.argmax(model_new.fc4.weight.detach().numpy()))\n",
    "\n",
    "print(np.argmax(model_new.fc4.bias.detach().numpy()))\n"
   ],
   "id": "ae2d7863982141eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episode_history, alpha_history, label='Alpha')\n",
    "plt.plot(episode_history, beta_history, label='Beta')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Alpha and Beta Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8617528db27232cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate_model(model, env)",
   "id": "9e83bb0b1595b3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2cc9d9d405c68e54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65fdbb225f8321f4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
