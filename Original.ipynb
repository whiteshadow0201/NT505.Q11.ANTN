{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_imports",
   "metadata": {},
   "source": [
    "## Sổ tay Tác nhân RL (Đã sửa lỗi)\n",
    "\n",
    "Sổ tay này tải môi trường, cấu hình GNN, và trọng số GNN đã huấn luyện (từ `Graph_Canonical_50.ipynb`) để chạy Tác nhân DQN."
   ]
  },
  {
   "cell_type": "code",
   "id": "imports_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:54:59.581296Z",
     "start_time": "2025-11-03T16:54:55.186594Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import dgl\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import random\n",
    "# Giả định các tệp utils này tồn tại trong thư mục của bạn\n",
    "# (Tệp graph_utils.py phải chứa EGraphSAGE_GraphAlign và DGI_GraphAlign)\n",
    "from utils.attack_algo_utils import *\n",
    "from utils.graph_utils import *\n",
    "from utils.utils import *\n",
    "\n",
    "print(\"--- CHUẨN BỊ MÔI TRƯỜNG ---\")\n",
    "\n",
    "# --- CHỌN PHIÊN BẢN THÍ NGHIỆM ---\n",
    "experiment_id = 1\n",
    "BASE_PATH = f'graphs/{experiment_id}'\n",
    "print(f\"Đang chạy thí nghiệm ID: {experiment_id} tại đường dẫn: {BASE_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CHUẨN BỊ MÔI TRƯỜNG ---\n",
      "Đang chạy thí nghiệm ID: 1 tại đường dẫn: graphs/1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "load_static_env",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:02:02.613922Z",
     "start_time": "2025-11-03T16:02:02.606255Z"
    }
   },
   "source": [
    "# ======================================================================\n",
    "# 1. TẢI DỮ LIỆU MÔI TRƯỜNG TĨNH\n",
    "# ======================================================================\n",
    "print(\"\\n--- Đang tải dữ liệu môi trường (tĩnh) ---\")\n",
    "STATIC_FILE_PATH = f\"{BASE_PATH}/graph_environment.pth\"\n",
    "NODE_EMB_PATH = f\"{BASE_PATH}/node_embeddings.npy\"\n",
    "\n",
    "try:\n",
    "    env_data = torch.load(STATIC_FILE_PATH, weights_only=False)\n",
    "    \n",
    "    G_original = env_data['G_original']\n",
    "    node_order = env_data['node_order']\n",
    "    node_map = env_data['node_map']\n",
    "    \n",
    "    # Lấy các đặc trưng GỐC (ví dụ: [8, 2])\n",
    "    original_node_features = env_data['node_features_original']\n",
    "    original_edge_features = env_data['edge_features_original']\n",
    "    g1 = env_data['g1'] # Đồ thị DGL gốc\n",
    "    \n",
    "    # Lấy cột priority (ví dụ: [8, 1])\n",
    "    static_priority_features = original_node_features[:, 1].unsqueeze(1) \n",
    "\n",
    "    nodes_emb = np.load(NODE_EMB_PATH) # Tải embedding đã huấn luyện\n",
    "\n",
    "    print(f\"Đã tải môi trường tĩnh từ '{STATIC_FILE_PATH}'\")\n",
    "    print(f\"Tổng số node: {len(node_order)}\")\n",
    "    print(f\"Shape của Node Embeddings (đã huấn luyện): {nodes_emb.shape}\")\n",
    "    print(f\"Shape của Đặc trưng Node Gốc: {original_node_features.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Không tìm thấy hoặc không đọc được tệp môi trường/embedding: {e}\")\n",
    "    print(\"Vui lòng chạy sổ tay 'Graph.ipynb' (huấn luyện) trước.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đang tải dữ liệu môi trường (tĩnh) ---\n",
      "LỖI: Không tìm thấy hoặc không đọc được tệp môi trường/embedding: [Errno 2] No such file or directory: 'graphs/1/graph_environment.pth'\n",
      "Vui lòng chạy sổ tay 'Graph.ipynb' (huấn luyện) trước.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "define_preprocessing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:02:02.625730Z",
     "start_time": "2025-11-03T16:02:02.616548Z"
    }
   },
   "source": [
    "# ======================================================================\n",
    "# 2. ĐỊNH NGHĨA HÀM TIỀN XỬ LÝ (PHẢI GIỐNG HỆT FILE HUẤN LUYỆN)\n",
    "# ======================================================================\n",
    "# (Chúng ta cần các hằng số và hàm này để xử lý\n",
    "#  đặc trưng [8, 2] thành [8, 50] trước khi đưa vào encoder)\n",
    "\n",
    "MAX_N_FEATURES = 50\n",
    "MAX_E_FEATURES = 50\n",
    "MARKER_VALUE = -999.0\n",
    "\n",
    "def normalize_and_pad_batch(feats_list, max_dim):\n",
    "    \"\"\"\n",
    "    Hàm này lấy một danh sách các tensor đặc trưng (từ các đồ thị khác nhau),\n",
    "    đệm chúng lên max_dim, sau đó chuẩn hóa từng cột một cách an toàn.\n",
    "    \"\"\"\n",
    "    padded_tensors = []\n",
    "    for feats in feats_list:\n",
    "        num_nodes_or_edges, num_feats = feats.shape\n",
    "        if num_feats > max_dim:\n",
    "            raise ValueError(f\"Đồ thị có {num_feats} đặc trưng, nhiều hơn MAX={max_dim}\")\n",
    "        \n",
    "        padded_tensor = torch.full((num_nodes_or_edges, max_dim), MARKER_VALUE, dtype=torch.float32)\n",
    "        padded_tensor[:, :num_feats] = feats\n",
    "        padded_tensors.append(padded_tensor)\n",
    "    \n",
    "    full_batch_tensor = torch.cat(padded_tensors, dim=0)\n",
    "    normalized_batch_tensor = full_batch_tensor.clone()\n",
    "    \n",
    "    for i in range(max_dim):\n",
    "        col = full_batch_tensor[:, i]\n",
    "        valid_mask = (col != MARKER_VALUE)\n",
    "        \n",
    "        if valid_mask.any():\n",
    "            valid_values = col[valid_mask]\n",
    "            mean = valid_values.mean()\n",
    "            std = valid_values.std() + 1e-6\n",
    "            normalized_batch_tensor[valid_mask, i] = (valid_values - mean) / std\n",
    "            normalized_batch_tensor[~valid_mask, i] = 0.0\n",
    "        else:\n",
    "            normalized_batch_tensor[:, i] = 0.0\n",
    "            \n",
    "    return normalized_batch_tensor\n",
    "\n",
    "print(\"Đã định nghĩa hàm tiền xử lý (padding + normalization).\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã định nghĩa hàm tiền xử lý (padding + normalization).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "load_gnn_model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:02:04.330999Z",
     "start_time": "2025-11-03T16:02:04.322055Z"
    }
   },
   "source": [
    "# ======================================================================\n",
    "# 3. TẢI MODEL GNN ĐÃ HUẤN LUYỆN (PHẦN ĐÃ SỬA)\n",
    "# ======================================================================\n",
    "print(\"\\n--- Đang tải cấu hình và trọng số GNN ---\")\n",
    "\n",
    "MODEL_STATE_PATH = f\"{BASE_PATH}/dgi_model_state_dict.pth\"\n",
    "CONFIG_FILE_PATH = f\"{BASE_PATH}/model_config.pth\"\n",
    "\n",
    "try:\n",
    "    # --- 3.1: Tải file cấu hình ---\n",
    "    config = torch.load(CONFIG_FILE_PATH, weights_only=False)\n",
    "    print(f\"Đã tải cấu hình: {config}\")\n",
    "\n",
    "    # --- 3.2: Khởi tạo mô hình rỗng TỪ CẤU HÌNH ĐÃ TẢI ---\n",
    "    # SỬA: Phải dùng EGraphSAGE_GraphAlign và DGI_GraphAlign\n",
    "    encoder = EGraphSAGE_GraphAlign(\n",
    "        config['NDIM_IN'],       # 50\n",
    "        config['EDIM'],          # 50\n",
    "        config['N_HIDDEN'],\n",
    "        config['N_OUT'],\n",
    "        config['N_LAYERS'],\n",
    "        F.leaky_relu,\n",
    "        config['NUM_EXPERTS'],   # Thêm tham số MoF\n",
    "        config['TOP_K']          # Thêm tham số MoF\n",
    "    )\n",
    "\n",
    "    dgi_model_to_load = DGI_GraphAlign(encoder) # SỬA: Dùng DGI_GraphAlign\n",
    "\n",
    "    # --- 3.3: Tải trọng số đã lưu ---\n",
    "    dgi_model_to_load.load_state_dict(torch.load(MODEL_STATE_PATH, weights_only=False))\n",
    "\n",
    "    # --- 3.4: Trích xuất encoder bạn cần ---\n",
    "    trained_encoder = dgi_model_to_load.encoder\n",
    "    trained_encoder.eval() # Chuyển sang chế độ dự đoán\n",
    "\n",
    "    print(f\"[THÀNH CÔNG] Đã tải và trích xuất GNN encoder (EGraphSAGE_GraphAlign).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[LỖI] Có lỗi xảy ra khi tải model: {e}\")\n",
    "    print(\"Hãy chắc chắn tệp 'graph_utils.py' của bạn chứa 'EGraphSAGE_GraphAlign' và 'DGI_GraphAlign'.\")\n",
    "    trained_encoder = None"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Đang tải cấu hình và trọng số GNN ---\n",
      "\n",
      "[LỖI] Có lỗi xảy ra khi tải model: [Errno 2] No such file or directory: 'graphs/1/model_config.pth'\n",
      "Hãy chắc chắn tệp 'graph_utils.py' của bạn chứa 'EGraphSAGE_GraphAlign' và 'DGI_GraphAlign'.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "define_dqn_logic",
   "metadata": {},
   "source": [
    "# ======================================================================\n",
    "# 4. ĐỊNH NGHĨA LOGIC HUẤN LUYỆN DQN\n",
    "# ======================================================================\n",
    "# (Nội dung của 2 cell DQN lớn từ file gốc của bạn)\n",
    "\n",
    "def train_dqn(env, num_episodes, batch_size=10, gamma=0.99, epsilon_start=1.0, epsilon_end=0.01, epsilon_decay=0.995):\n",
    "    global best_checkpoint, best_episode\n",
    "    # 1. Reset env để lấy state (embedding) ban đầu\n",
    "    state = env.reset() # state giờ là Tensor [num_nodes, embedding_dim]\n",
    "\n",
    "    # 2. Tính toán state_size đã làm phẳng\n",
    "    num_nodes = state.shape[0]\n",
    "    embedding_dim = state.shape[1]\n",
    "    state_size = num_nodes * embedding_dim  # <--- Kích thước input mới cho DQN\n",
    "\n",
    "    action_space_size = env.get_action_space_size()\n",
    "\n",
    "    print('state_size (flattened):', state_size) # <--- Cập nhật log\n",
    "    print('action_space_size', action_space_size)\n",
    "\n",
    "    # 3. Khởi tạo DQN với state_size mới\n",
    "    policy_net = DQN(state_size, action_space_size)\n",
    "    target_net = DQN(state_size, action_space_size)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=0.001)\n",
    "    replay_buffer = ReplayBuffer(capacity=10000)\n",
    "    epsilon = epsilon_start\n",
    "    total_reward = 0\n",
    "    dsp = 0\n",
    "    best_dsp = 0\n",
    "    interval_check = num_episodes // 10\n",
    "    interval_save = num_episodes // 5\n",
    "    best_checkpoint = None\n",
    "    best_episode = 0\n",
    "\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        # Reset state cho các episode sau\n",
    "        if episode > 1:\n",
    "            state = env.reset() # <--- state là Tensor embedding\n",
    "\n",
    "        done = False\n",
    "        exploration_counter = defaultdict(int)\n",
    "\n",
    "        while not done:\n",
    "            if random.random() < epsilon:\n",
    "                action_idx = sample_valid_index(action_space_size, env.num_honeypot_nodes, exploration_counter)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    # --- THAY ĐỔI: Flatten state tensor ---\n",
    "                    # Chuyển [N, D] -> [1, N*D]\n",
    "                    state_tensor = state.flatten().unsqueeze(0)\n",
    "                    q_values = policy_net(state_tensor).squeeze(0)\n",
    "\n",
    "                    # (Logic lọc q_values giữ nguyên)\n",
    "                    valid_indices = [idx for idx in range(action_space_size) if is_valid_index(idx, env.num_honeypot_nodes)]\n",
    "                    valid_q_values = q_values[valid_indices]\n",
    "                    max_idx_in_valid = torch.argmax(valid_q_values).item()\n",
    "                    action_idx = valid_indices[max_idx_in_valid]\n",
    "\n",
    "            action = index_to_action(action_idx, env.num_honeypot_nodes)\n",
    "\n",
    "            # --- next_state giờ cũng là Tensor embedding ---\n",
    "            next_state, reward, done, path, captured = env.step(action)\n",
    "            action_idx = action_to_index(action, env.num_honeypot_nodes)\n",
    "\n",
    "            # Store experience (state và next_state là Tensors)\n",
    "            replay_buffer.push(state, action_idx, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if reward == 1:\n",
    "                dsp += 1\n",
    "\n",
    "            # Train if enough experiences\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                # --- THAY ĐỔI: Replay buffer giờ trả về Tensors ---\n",
    "                states_batch, actions_batch, rewards_batch, next_states_batch, dones_batch = replay_buffer.sample(batch_size)\n",
    "\n",
    "                # states_batch là [B, N, D], actions_batch là [B], rewards_batch là [B, 1], ...\n",
    "\n",
    "                # --- THAY ĐỔI: Flatten state batches ---\n",
    "                # Chuyển [B, N, D] -> [B, N*D]\n",
    "                states_flat = states_batch.flatten(start_dim=1)\n",
    "                next_states_flat = next_states_batch.flatten(start_dim=1)\n",
    "\n",
    "                # Compute Q-values\n",
    "                q_values_all = policy_net(states_flat)\n",
    "                # Dùng actions_batch để lấy Q-value của action đã chọn\n",
    "                q_values = q_values_all.gather(1, actions_batch.long().unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                # Compute target Q-values\n",
    "                with torch.no_grad():\n",
    "                    # Dùng next_states_flat\n",
    "                    next_q_values = target_net(next_states_flat).max(1)[0]\n",
    "                    # Squeeze rewards và dones để khớp kích thước [B]\n",
    "                    targets = rewards_batch.squeeze(1) + (1 - dones_batch.squeeze(1)) * gamma * next_q_values\n",
    "\n",
    "                # Compute loss\n",
    "                loss = nn.MSELoss()(q_values, targets)\n",
    "\n",
    "                # Optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update target network\n",
    "        if episode % 10 == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
    "\n",
    "        # Logging (Giữ nguyên)\n",
    "        if episode % interval_check == 0:\n",
    "            placement = []\n",
    "            for i in range(2):\n",
    "                node_idx = np.argmax(action[i])\n",
    "                node_name = env.honeypot_nodes[node_idx]\n",
    "                placement.append(f\"Honeypot {i} -> {node_name}\\n\")\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}, Defense Success Probability: {dsp/interval_check}%\\n\")\n",
    "            print(\"\".join(placement))\n",
    "            print(path)\n",
    "            total_reward = 0\n",
    "\n",
    "            if dsp > best_dsp:\n",
    "                best_dsp = dsp\n",
    "                best_episode = episode\n",
    "                best_checkpoint = {\n",
    "                    'policy_net_state_dict': deepcopy(policy_net.state_dict()),\n",
    "                    'target_net_state_dict': deepcopy(target_net.state_dict()),\n",
    "                    'optimizer_state_dict': deepcopy(optimizer.state_dict()),\n",
    "                }\n",
    "            dsp = 0\n",
    "\n",
    "        # Save (Giữ nguyên)\n",
    "        if (episode + 1) % interval_save == 0 and best_checkpoint is not None:\n",
    "            path = f'./Saved_Model/dqn_model.pth'\n",
    "            torch.save({\n",
    "                'policy_net_state_dict': best_checkpoint['policy_net_state_dict'],\n",
    "                'target_net_state_dict': best_checkpoint['target_net_state_dict'],\n",
    "                'optimizer_state_dict': best_checkpoint['optimizer_state_dict'],\n",
    "                'episode': best_episode},\n",
    "                path)\n",
    "            print(f'Saved model with best DSP {best_dsp} at episode {best_episode} to {path}')\n",
    "\n",
    "            best_dsp = 0\n",
    "            best_episode = 0\n",
    "            best_checkpoint = None\n",
    "\n",
    "    return policy_net\n",
    "\n",
    "\n",
    "print(\"Đã định nghĩa logic DQN.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "init_env_and_train",
   "metadata": {
    "tags": [
     "CELL QUAN TRỌNG ĐÃ SỬA"
    ]
   },
   "source": [
    "# ======================================================================\n",
    "# 5. KHỞI TẠO MÔI TRƯỜNG & HUẤN LUYỆN (PHẦN ĐÃ SỬA)\n",
    "# ======================================================================\n",
    "print(\"\\n--- Khởi tạo Môi trường RL ---\")\n",
    "\n",
    "# Initialize environment and train\n",
    "algo = global_weighted_random_attack\n",
    "G_new_env = deepcopy(G_original)\n",
    "\n",
    "# --- SỬA LỖI LOGIC QUAN TRỌNG ---\n",
    "# Chúng ta phải xử lý (pad + norm) các đặc trưng GỐC\n",
    "# để chúng khớp với đầu vào 50-dim mà encoder mong đợi.\n",
    "print(\"Xử lý đặc trưng gốc sang dạng 50-dim (Padding + Norm)...\")\n",
    "nfeats_processed_for_env = normalize_and_pad_batch([original_node_features], MAX_N_FEATURES)\n",
    "efeats_processed_for_env = normalize_and_pad_batch([original_edge_features], MAX_E_FEATURES)\n",
    "print(f\"Đã xử lý đặc trưng node: {nfeats_processed_for_env.shape}\")\n",
    "print(f\"Đã xử lý đặc trưng cạnh: {efeats_processed_for_env.shape}\")\n",
    "\n",
    "env = NetworkEnv(\n",
    "    G_new=G_new_env,\n",
    "    attack_fn=algo,\n",
    "    g_dgl=g1, # Sử dụng g1 (DGL graph gốc)\n",
    "    encoder=trained_encoder, # Encoder đã huấn luyện (mong đợi 50-dim)\n",
    "    \n",
    "    # --- SỬA LỖI: Truyền vào các đặc trưng ĐÃ XỬ LÝ (50-dim) ---\n",
    "    original_node_features=nfeats_processed_for_env,\n",
    "    original_edge_features=efeats_processed_for_env,\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    node_map=node_map,\n",
    "    goal=\"Data Server\"  # (Hoặc goal bạn muốn)\n",
    ")\n",
    "\n",
    "# --- 3. HUẤN LUYỆN ---\n",
    "num_episode = 2000\n",
    "if not os.path.exists('./Saved_Model'):\n",
    "    os.makedirs('./Saved_Model')\n",
    "\n",
    "model = train_dqn(env, num_episode)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "evaluate_model_cell",
   "metadata": {},
   "source": [
    "evaluate_model(model, env)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "visualize_graph_cell",
   "metadata": {},
   "source": [
    "# --- Trực quan hóa đồ thị gốc (từ cell cũ) ---\n",
    "plt.figure(figsize=(30, 36))\n",
    "pos = nx.spring_layout(G_original) # Dùng G_original\n",
    "\n",
    "nx.draw_networkx_nodes(G_original, pos, node_color='orange', node_size=2000)\n",
    "nx.draw_networkx_labels(G_original, pos, font_size=10, font_weight='bold')\n",
    "\n",
    "nx.draw_networkx_edges(\n",
    "    G_original, pos,\n",
    "    edge_color='gray',\n",
    "    arrows=True,\n",
    "    arrowstyle='->',\n",
    "    arrowsize=50,\n",
    "    connectionstyle='arc3,rad=0.2'\n",
    ")\n",
    "\n",
    "# Vẽ nhãn trên cạnh\n",
    "edge_labels = {(u, v): f\"user={d['user']}, root={d['root']}\" for u, v, d in G_original.edges(data=True)}\n",
    "nx.draw_networkx_edge_labels(G_original, pos, edge_labels=edge_labels, font_size=12)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fc9baac7f5254d3a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
